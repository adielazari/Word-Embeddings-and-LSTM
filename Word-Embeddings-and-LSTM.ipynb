{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ass3_deep_learnning_4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZn0hxp2M89j",
        "colab_type": "code",
        "outputId": "7b9efbac-5c5e-4b5c-e6d6-570e05afc3ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUT_gIj1NfH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "train_data=pd.read_csv('/content/drive/My Drive/word embedding/train.csv',index_col='id',encoding='Latin-1')\n",
        "test_data=pd.read_csv('/content/drive/My Drive/word embedding/test.csv',index_col='id', encoding='Latin-1')\n",
        "test_data = test_data[test_data['relevance']!=-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3PndPxuPJQF",
        "colab_type": "text"
      },
      "source": [
        "#Pre processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF87QbIyMzEB",
        "colab_type": "text"
      },
      "source": [
        "Clean sentances - without stop words and with stemming  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVjit9sCODd4",
        "colab_type": "code",
        "outputId": "c8050365-f860-4912-8099-feee79a8e509",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "sw=stopwords.words('english')\n",
        "ps = PorterStemmer()\n",
        "def stop_words(data):\n",
        "  toReturn=''\n",
        "  for word in data.split(' '):\n",
        "    if word.lower() not in sw:\n",
        "      toReturn = toReturn + ps.stem(word.lower()) + ' '\n",
        "  return toReturn.strip()\n",
        "def clean_sentance(df):\n",
        "  data=df.copy()\n",
        "  data['product_title']=data['product_title'].apply(lambda x: stop_words(x))\n",
        "  data['search_term']=data['search_term'].apply(lambda x: stop_words(x))\n",
        "  return data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYKKfioPQK_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_to_chars(df):\n",
        "  data=df.copy()\n",
        "  data['product_title']=data['product_title'].apply(lambda x: [char for char in x if char != ' '])\n",
        "  data['search_term']=data['search_term'].apply(lambda x: [char for char in x if char != ' '])\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_l8aOwpsU7NB",
        "colab_type": "code",
        "outputId": "60868eb3-3463-442d-e45e-6790124ae5d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        }
      },
      "source": [
        "train_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_uid</th>\n",
              "      <th>product_title</th>\n",
              "      <th>search_term</th>\n",
              "      <th>relevance</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100001</td>\n",
              "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
              "      <td>angle bracket</td>\n",
              "      <td>3.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100001</td>\n",
              "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
              "      <td>l bracket</td>\n",
              "      <td>2.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>100002</td>\n",
              "      <td>BEHR Premium Textured DeckOver 1-gal. #SC-141 ...</td>\n",
              "      <td>deck over</td>\n",
              "      <td>3.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>100005</td>\n",
              "      <td>Delta Vero 1-Handle Shower Only Faucet Trim Ki...</td>\n",
              "      <td>rain shower head</td>\n",
              "      <td>2.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>100005</td>\n",
              "      <td>Delta Vero 1-Handle Shower Only Faucet Trim Ki...</td>\n",
              "      <td>shower only faucet</td>\n",
              "      <td>2.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221457</th>\n",
              "      <td>206638</td>\n",
              "      <td>Atlantic Windowpane 576 CD or 192 DVD Blu-Ray ...</td>\n",
              "      <td>tv riser glass</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221458</th>\n",
              "      <td>206639</td>\n",
              "      <td>Philips 40-Watt Halogen R20 Flood Light Bulb (...</td>\n",
              "      <td>r20 halogen light</td>\n",
              "      <td>3.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221463</th>\n",
              "      <td>206641</td>\n",
              "      <td>Schlage Camelot In-Active Aged Bronze Handlese...</td>\n",
              "      <td>schlage lock siena half dummy knob with</td>\n",
              "      <td>2.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221471</th>\n",
              "      <td>206648</td>\n",
              "      <td>Plastec 11 in. x 24 in. Rose Garden Wall Decor...</td>\n",
              "      <td>zen garden  decor</td>\n",
              "      <td>3.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221473</th>\n",
              "      <td>206650</td>\n",
              "      <td>LICHTENBERG Pool Blue No. 918 Millennial Ryan ...</td>\n",
              "      <td>fine sheer curtain 63 inches</td>\n",
              "      <td>2.33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>74067 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        product_uid  ... relevance\n",
              "id                   ...          \n",
              "2            100001  ...      3.00\n",
              "3            100001  ...      2.50\n",
              "9            100002  ...      3.00\n",
              "16           100005  ...      2.33\n",
              "17           100005  ...      2.67\n",
              "...             ...  ...       ...\n",
              "221457       206638  ...      1.00\n",
              "221458       206639  ...      3.00\n",
              "221463       206641  ...      2.33\n",
              "221471       206648  ...      3.00\n",
              "221473       206650  ...      2.33\n",
              "\n",
              "[74067 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo5FT8IkRb-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train=clean_sentance(train_data)\n",
        "test=clean_sentance(test_data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zck_xS8BTjiJ",
        "colab_type": "code",
        "outputId": "12e0ae3e-5fe0-416c-9259-ed64b473f8c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        }
      },
      "source": [
        "train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_uid</th>\n",
              "      <th>product_title</th>\n",
              "      <th>search_term</th>\n",
              "      <th>relevance</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100001</td>\n",
              "      <td>simpson strong-ti 12-gaug angl</td>\n",
              "      <td>angl bracket</td>\n",
              "      <td>3.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100001</td>\n",
              "      <td>simpson strong-ti 12-gaug angl</td>\n",
              "      <td>l bracket</td>\n",
              "      <td>2.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>100002</td>\n",
              "      <td>behr premium textur deckov 1-gal. #sc-141 tugb...</td>\n",
              "      <td>deck</td>\n",
              "      <td>3.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>100005</td>\n",
              "      <td>delta vero 1-handl shower faucet trim kit chro...</td>\n",
              "      <td>rain shower head</td>\n",
              "      <td>2.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>100005</td>\n",
              "      <td>delta vero 1-handl shower faucet trim kit chro...</td>\n",
              "      <td>shower faucet</td>\n",
              "      <td>2.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221457</th>\n",
              "      <td>206638</td>\n",
              "      <td>atlant windowpan 576 cd 192 dvd blu-ray game m...</td>\n",
              "      <td>tv riser glass</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221458</th>\n",
              "      <td>206639</td>\n",
              "      <td>philip 40-watt halogen r20 flood light bulb (1...</td>\n",
              "      <td>r20 halogen light</td>\n",
              "      <td>3.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221463</th>\n",
              "      <td>206641</td>\n",
              "      <td>schlage camelot in-act age bronz handleset lef...</td>\n",
              "      <td>schlage lock siena half dummi knob</td>\n",
              "      <td>2.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221471</th>\n",
              "      <td>206648</td>\n",
              "      <td>plastec 11 in. x 24 in. rose garden wall decor...</td>\n",
              "      <td>zen garden  decor</td>\n",
              "      <td>3.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221473</th>\n",
              "      <td>206650</td>\n",
              "      <td>lichtenberg pool blue no. 918 millenni ryan he...</td>\n",
              "      <td>fine sheer curtain 63 inch</td>\n",
              "      <td>2.33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>74067 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        product_uid  ... relevance\n",
              "id                   ...          \n",
              "2            100001  ...      3.00\n",
              "3            100001  ...      2.50\n",
              "9            100002  ...      3.00\n",
              "16           100005  ...      2.33\n",
              "17           100005  ...      2.67\n",
              "...             ...  ...       ...\n",
              "221457       206638  ...      1.00\n",
              "221458       206639  ...      3.00\n",
              "221463       206641  ...      2.33\n",
              "221471       206648  ...      3.00\n",
              "221473       206650  ...      2.33\n",
              "\n",
              "[74067 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbhUUDehWckg",
        "colab_type": "code",
        "outputId": "b7c10653-2385-49dc-f857-01a2b7dc6643",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import *\n",
        "from keras.models import Model\n",
        "from keras.optimizers import *"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAlSJPwEW1fT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_s1=train['product_title']\n",
        "train_s2=train['search_term']\n",
        "y=train['relevance']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qz25MM9K9TL",
        "colab_type": "code",
        "outputId": "9b1e0766-ff11-4d76-a331-921bbd8683b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "train_s1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id\n",
              "2                            simpson strong-ti 12-gaug angl\n",
              "3                            simpson strong-ti 12-gaug angl\n",
              "9         behr premium textur deckov 1-gal. #sc-141 tugb...\n",
              "16        delta vero 1-handl shower faucet trim kit chro...\n",
              "17        delta vero 1-handl shower faucet trim kit chro...\n",
              "                                ...                        \n",
              "221457    atlant windowpan 576 cd 192 dvd blu-ray game m...\n",
              "221458    philip 40-watt halogen r20 flood light bulb (1...\n",
              "221463    schlage camelot in-act age bronz handleset lef...\n",
              "221471    plastec 11 in. x 24 in. rose garden wall decor...\n",
              "221473    lichtenberg pool blue no. 918 millenni ryan he...\n",
              "Name: product_title, Length: 74067, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cXrF02hK9Yg",
        "colab_type": "code",
        "outputId": "61f27869-9e28-4b7b-c659-00d0c23e2230",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id\n",
              "2         3.00\n",
              "3         2.50\n",
              "9         3.00\n",
              "16        2.33\n",
              "17        2.67\n",
              "          ... \n",
              "221457    1.00\n",
              "221458    3.00\n",
              "221463    2.33\n",
              "221471    3.00\n",
              "221473    2.33\n",
              "Name: relevance, Length: 74067, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6ZaYszCGCR1",
        "colab_type": "text"
      },
      "source": [
        "Replase symbols that appear fewer times with a placeholder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osgtJdhE2m_I",
        "colab_type": "code",
        "outputId": "2ccc3573-4d1c-42cf-b46d-f27e4b417cd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from collections import Counter\n",
        "unique_symbols = Counter()\n",
        "\n",
        "for _, message in train_s1.iteritems():\n",
        "    unique_symbols.update(message)\n",
        "    \n",
        "print(\"Unique symbols:\", len(unique_symbols))\n",
        "\n",
        "\n",
        "# Find symbols that appear fewer times than the threshold:\n",
        "\n",
        "uncommon_symbols = list()\n",
        "\n",
        "for symbol, count in unique_symbols.items():\n",
        "    if count < 5:\n",
        "        uncommon_symbols.append(symbol)\n",
        "\n",
        "print(\"Uncommon symbols:\", len(uncommon_symbols))\n",
        "\n",
        "\n",
        "# Replace them with a placeholder:\n",
        "\n",
        "DUMMY = uncommon_symbols[0]\n",
        "tr_table = str.maketrans(\"\".join(uncommon_symbols), DUMMY * len(uncommon_symbols))\n",
        "\n",
        "train_s1 = train_s1.apply(lambda x: x.translate(tr_table))\n",
        "\n",
        "\n",
        "# We will need the number of unique symbols further down when we will decide on the dimensionality of inputs.\n",
        "\n",
        "num_unique_symbols = len(unique_symbols) - len(uncommon_symbols) + 1 "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique symbols: 75\n",
            "Uncommon symbols: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VesWaiGvOu6L",
        "colab_type": "text"
      },
      "source": [
        "Tokenizer of product_title feture by characters\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBKP4TMHK9i_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(\n",
        "    char_level=True,\n",
        "    filters=None,\n",
        "    lower=False,\n",
        ")\n",
        "\n",
        "tokenizer.fit_on_texts(train_s1)\n",
        "train_s1_seq = tokenizer.texts_to_sequences(train_s1)\n",
        "train_s1_seq = pad_sequences(train_s1_seq, maxlen=300, padding='post')\n",
        "#train_s2_seq = pad_sequences(train_s2, padding='post')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2-1W3lYGcqB",
        "colab_type": "text"
      },
      "source": [
        "Replase symbols that appear fewer times with a placeholder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgpjtlWj5off",
        "colab_type": "code",
        "outputId": "9e053912-0334-486b-880a-3f961c39f47c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from collections import Counter\n",
        "unique_symbols = Counter()\n",
        "\n",
        "for _, message in train_s2.iteritems():\n",
        "    unique_symbols.update(message)\n",
        "    \n",
        "print(\"Unique symbols:\", len(unique_symbols))\n",
        "\n",
        "\n",
        "# Find symbols that appear fewer times than the threshold:\n",
        "\n",
        "uncommon_symbols = list()\n",
        "\n",
        "for symbol, count in unique_symbols.items():\n",
        "    if count < 5:\n",
        "        uncommon_symbols.append(symbol)\n",
        "\n",
        "print(\"Uncommon symbols:\", len(uncommon_symbols))\n",
        "\n",
        "\n",
        "# Replace them with a placeholder:\n",
        "\n",
        "DUMMY = uncommon_symbols[0]\n",
        "tr_table = str.maketrans(\"\".join(uncommon_symbols), DUMMY * len(uncommon_symbols))\n",
        "\n",
        "train_s2 = train_s2.apply(lambda x: x.translate(tr_table))\n",
        "\n",
        "\n",
        "# We will need the number of unique symbols further down when we will decide on the dimensionality of inputs.\n",
        "\n",
        "num_unique_symbols2 = len(unique_symbols) - len(uncommon_symbols) + 1 "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique symbols: 51\n",
            "Uncommon symbols: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLEnCyKePkPq",
        "colab_type": "text"
      },
      "source": [
        "Tokenizer of search_term feture by characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a85lRjLGuXWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(\n",
        "    char_level=True,\n",
        "    filters=None,\n",
        "    lower=False,\n",
        ")\n",
        "tokenizer.fit_on_texts(train_s2)\n",
        "train_s2_seq = tokenizer.texts_to_sequences(train_s2)\n",
        "train_s2_seq = pad_sequences(train_s2_seq, maxlen=300, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoDO5WSW11m1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_s1_seq=train_s1_seq.reshape(-1,1,300)\n",
        "train_s2_seq=train_s2_seq.reshape(-1,1,300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXdbOTz2GmvJ",
        "colab_type": "text"
      },
      "source": [
        "# Model based character level\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ln9whOb9wQx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train1, x_test1, y_train, y_test = train_test_split(train_s1_seq, y, test_size=0.2)\n",
        "x_train2, x_test2, y_train2, y_test = train_test_split(train_s2_seq, y, test_size=0.2)\n",
        "x_train1, x_val1, y_train, y_val = train_test_split(x_train1, y_train, test_size=0.1)\n",
        "x_train2, x_val2, y_train2, y_val = train_test_split(x_train2, y_train2, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gF1Xs6YSIkbN",
        "colab_type": "code",
        "outputId": "134362ea-73de-4151-bca8-a119d8d05310",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "import keras.backend as K\n",
        "def cosine_distance(vests):\n",
        "    x, y = vests\n",
        "    x = K.l2_normalize(x, axis=-1)\n",
        "    y = K.l2_normalize(y, axis=-1)\n",
        "    return -K.mean(x * y, axis=-1, keepdims=True)\n",
        "\n",
        "def cos_dist_output_shape(shapes):\n",
        "    shape1, shape2 = shapes\n",
        "    return (shape1[0],1)\n",
        "input_1 = Input(shape=(1,300))\n",
        "input_2 = Input(shape=(1,300))\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "        return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
        "common_lstm = LSTM(64,return_sequences=True, activation=\"relu\")\n",
        "vector_1 = common_lstm(input_1)\n",
        "vector_1 = Flatten()(vector_1)\n",
        "\n",
        "vector_2 = common_lstm(input_2)\n",
        "vector_2 = Flatten()(vector_2)\n",
        "\n",
        "x3 = Subtract()([vector_1, vector_2])\n",
        "x4= Add()([vector_1, vector_2])\n",
        "x5=Multiply()([vector_1, vector_2])\n",
        "\n",
        "    \n",
        "conc = Concatenate(axis=-1)([x5,x4, x3])\n",
        "\n",
        "x = Dense(100, activation=\"relu\", name='conc_layer')(conc)\n",
        "x = Dropout(0.01)(x)\n",
        "out = Dense(1, activation=\"relu\", name = 'out')(x)\n",
        "\n",
        "model = Model([input_1, input_2], out)\n",
        "model.compile(loss=root_mean_squared_error, optimizer=Adam(0.00001))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASD_KUNM0IOu",
        "colab_type": "code",
        "outputId": "ba0dc925-dee7-46b6-d85d-3a4273c87781",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        }
      },
      "source": [
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 1, 300)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 1, 300)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 1, 64)        93440       input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 64)           0           lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 64)           0           lstm_1[1][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "multiply_1 (Multiply)           (None, 64)           0           flatten_1[0][0]                  \n",
            "                                                                 flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 64)           0           flatten_1[0][0]                  \n",
            "                                                                 flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "subtract_1 (Subtract)           (None, 64)           0           flatten_1[0][0]                  \n",
            "                                                                 flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 192)          0           multiply_1[0][0]                 \n",
            "                                                                 add_1[0][0]                      \n",
            "                                                                 subtract_1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conc_layer (Dense)              (None, 100)          19300       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 100)          0           conc_layer[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "out (Dense)                     (None, 1)            101         dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 112,841\n",
            "Trainable params: 112,841\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwRn5IW0IsM1",
        "colab_type": "code",
        "outputId": "7d435f41-2855-4880-9b0b-25913568da74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import time\n",
        "siam_time=time.time()\n",
        "model.fit([x_train1,x_train2],y_train.values.reshape(-1,1), epochs = 20,\n",
        "          batch_size=64, validation_data=([x_val1, x_val2],y_val.values.reshape(-1,1)))\n",
        "siam_time=time.time()-siam_time"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 53327 samples, validate on 5926 samples\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "53327/53327 [==============================] - 18s 337us/step - loss: 1.6474 - val_loss: 1.2738\n",
            "Epoch 2/20\n",
            "53327/53327 [==============================] - 8s 143us/step - loss: 1.1341 - val_loss: 1.0182\n",
            "Epoch 3/20\n",
            "53327/53327 [==============================] - 7s 140us/step - loss: 0.9651 - val_loss: 0.9072\n",
            "Epoch 4/20\n",
            "53327/53327 [==============================] - 7s 139us/step - loss: 0.8798 - val_loss: 0.8431\n",
            "Epoch 5/20\n",
            "53327/53327 [==============================] - 8s 148us/step - loss: 0.8275 - val_loss: 0.7976\n",
            "Epoch 6/20\n",
            "53327/53327 [==============================] - 8s 147us/step - loss: 0.7890 - val_loss: 0.7641\n",
            "Epoch 7/20\n",
            "53327/53327 [==============================] - 8s 143us/step - loss: 0.7555 - val_loss: 0.7356\n",
            "Epoch 8/20\n",
            "53327/53327 [==============================] - 8s 141us/step - loss: 0.7324 - val_loss: 0.7121\n",
            "Epoch 9/20\n",
            "53327/53327 [==============================] - 7s 140us/step - loss: 0.7102 - val_loss: 0.6936\n",
            "Epoch 10/20\n",
            "53327/53327 [==============================] - 7s 140us/step - loss: 0.6942 - val_loss: 0.6794\n",
            "Epoch 11/20\n",
            "53327/53327 [==============================] - 7s 138us/step - loss: 0.6791 - val_loss: 0.6662\n",
            "Epoch 12/20\n",
            "53327/53327 [==============================] - 7s 130us/step - loss: 0.6657 - val_loss: 0.6543\n",
            "Epoch 13/20\n",
            "53327/53327 [==============================] - 7s 135us/step - loss: 0.6551 - val_loss: 0.6451\n",
            "Epoch 14/20\n",
            "53327/53327 [==============================] - 7s 132us/step - loss: 0.6444 - val_loss: 0.6371\n",
            "Epoch 15/20\n",
            "53327/53327 [==============================] - 7s 134us/step - loss: 0.6336 - val_loss: 0.6291\n",
            "Epoch 16/20\n",
            "53327/53327 [==============================] - 7s 134us/step - loss: 0.6280 - val_loss: 0.6232\n",
            "Epoch 17/20\n",
            "53327/53327 [==============================] - 7s 134us/step - loss: 0.6202 - val_loss: 0.6180\n",
            "Epoch 18/20\n",
            "53327/53327 [==============================] - 7s 136us/step - loss: 0.6132 - val_loss: 0.6131\n",
            "Epoch 19/20\n",
            "53327/53327 [==============================] - 7s 134us/step - loss: 0.6072 - val_loss: 0.6088\n",
            "Epoch 20/20\n",
            "53327/53327 [==============================] - 7s 135us/step - loss: 0.6014 - val_loss: 0.6049\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFuLNyXhKL77",
        "colab_type": "text"
      },
      "source": [
        "Evaluation by RMSE and MAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keR1N0ggvQnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "siam_pred_time=time.time()\n",
        "siam_train_pred=model.predict([x_train1,x_train2])\n",
        "siam_val_pred=model.predict([x_val1, x_val2])\n",
        "siam_test_pred=model.predict([x_test1, x_test2])\n",
        "siam_pred_time=time.time()-siam_pred_time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzg-pNZ2yA8O",
        "colab_type": "code",
        "outputId": "8cba704d-4278-46ae-bbc6-392de5d243e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
        "from math import sqrt\n",
        "lstm_rmse_train = sqrt(mean_squared_error(y_train, siam_train_pred))\n",
        "lstm_rmse_val = sqrt(mean_squared_error(y_val, siam_val_pred))\n",
        "lstm_rmse_test = sqrt(mean_squared_error(y_test, siam_test_pred))\n",
        "lstm_mae_train=mean_absolute_error(y_train, siam_train_pred)\n",
        "lstm_mae_val=mean_absolute_error(y_val, siam_val_pred)\n",
        "lstm_mae_test=mean_absolute_error(y_test, siam_test_pred)\n",
        "print('******************LSTM***********************')\n",
        "print(\"TRAIN: RMSE: %f , MAE: %f\" % (lstm_rmse_train,lstm_mae_train))\n",
        "print(\"VALIDATE: RMSE: %f , MAE: %f\" % (lstm_rmse_val,lstm_mae_val))\n",
        "print(\"TEST: RMSE: %f , MAE: %f\" % (lstm_rmse_test,lstm_mae_test))\n",
        "print('taining time : ' + str(siam_time))\n",
        "print('prediction time : ' + str(siam_pred_time))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "******************LSTM***********************\n",
            "TRAIN: RMSE: 0.583946 , MAE: 0.475784\n",
            "VALIDATE: RMSE: 0.606638 , MAE: 0.494308\n",
            "TEST: RMSE: 0.606863 , MAE: 0.496238\n",
            "taining time : 159.12244248390198\n",
            "prediction time : 7.081084489822388\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1XPVfm2LE4o",
        "colab_type": "text"
      },
      "source": [
        "# Naive linear regression on character level\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKyrGemQsPXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LinearRegression\n",
        " #dummy function for CountVectorizer\n",
        "def dummy_fun(doc):\n",
        "    return doc\n",
        "\n",
        "lr_model=Pipeline([('vect', CountVectorizer(analyzer='char',\n",
        "     tokenizer=dummy_fun,\n",
        "     preprocessor=dummy_fun,\n",
        "     token_pattern=None)),\n",
        "               ('clf', LinearRegression())\n",
        "              ])\n",
        "train['combined'] = train[['product_title', 'search_term']].apply(lambda x: ''.join(x), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f5ZtlHzEX-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_chars(df):\n",
        "  data=df.copy()\n",
        "  data['combined']=data['combined'].apply(lambda x: [char for char in x if char != ' '])\n",
        "  return data\n",
        "#train=split_chars(train)\n",
        "train['combined']=train['combined'].astype(str)\n",
        "lr_train, lr_test, y_train, y_test = train_test_split(train['combined'], y, test_size=0.2)\n",
        "lr_train, lr_val, y_train, y_val = train_test_split(lr_train, y_train, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVTJpFCHXJpm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_time=time.time()\n",
        "lr_model.fit(lr_train,y_train)\n",
        "lr_time=time.time()-lr_time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEOr6ocTou8u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_pred_time=time.time()\n",
        "lr_val_pred=lr_model.predict(lr_val)\n",
        "lr_test_pred=lr_model.predict(lr_test)\n",
        "lr_train_pred=lr_model.predict(lr_train)\n",
        "lr_pred_time=time.time()-lr_pred_time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EInGsxQ7ZNYy",
        "colab_type": "code",
        "outputId": "0d3cd1cd-4b3d-4804-9dd6-4d3fde290c39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
        "from math import sqrt\n",
        "lr_rmse_train = sqrt(mean_squared_error(y_train, lr_train_pred))\n",
        "lr_rmse_val = sqrt(mean_squared_error(y_val, lr_val_pred))\n",
        "lr_rmse_test = sqrt(mean_squared_error(y_test, lr_test_pred))\n",
        "lr_mae_train=mean_absolute_error(y_train, lr_train_pred)\n",
        "lr_mae_val=mean_absolute_error(y_val, lr_val_pred)\n",
        "lr_mae_test=mean_absolute_error(y_test, lr_test_pred)\n",
        "print('******************naive linear regression***********************')\n",
        "print(\"TRAIN: RMSE: %f , MAE: %f\" % (lr_rmse_train,lr_mae_train))\n",
        "print(\"VALIDATE: RMSE: %f , MAE: %f\" % (lr_rmse_val,lr_mae_val))\n",
        "print(\"TEST: RMSE: %f , MAE: %f\" % (lr_rmse_test,lr_mae_test))\n",
        "print('test time : ' + str(lr_time))\n",
        "print('prediction time : ' + str(lr_pred_time))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "******************naive linear regression***********************\n",
            "TRAIN: RMSE: 0.531074 , MAE: 0.435518\n",
            "VALIDATE: RMSE: 0.531780 , MAE: 0.435848\n",
            "TEST: RMSE: 0.530758 , MAE: 0.435205\n",
            "test time : 2.101875066757202\n",
            "prediction time : 1.6222164630889893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjt3-JkLLddo",
        "colab_type": "text"
      },
      "source": [
        "#Features extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a4tmT_moXwa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_extract=model.layers[-3].output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeASB3UiCiFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "newModel=Model([input_1, input_2], feature_extract)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHwRi9zLCwV3",
        "colab_type": "code",
        "outputId": "10461f2e-2c71-4ec0-dfd8-4a9edacbd64c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "newModel.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 1, 300)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 1, 300)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 1, 64)        93440       input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 64)           0           lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 64)           0           lstm_1[1][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "multiply_1 (Multiply)           (None, 64)           0           flatten_1[0][0]                  \n",
            "                                                                 flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 64)           0           flatten_1[0][0]                  \n",
            "                                                                 flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "subtract_1 (Subtract)           (None, 64)           0           flatten_1[0][0]                  \n",
            "                                                                 flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 192)          0           multiply_1[0][0]                 \n",
            "                                                                 add_1[0][0]                      \n",
            "                                                                 subtract_1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conc_layer (Dense)              (None, 100)          19300       concatenate_1[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 112,740\n",
            "Trainable params: 112,740\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN79ECZ0qTYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fe_train=newModel.predict(([x_train1,x_train2]))\n",
        "fe_val=newModel.predict(([x_val1,x_val2]))\n",
        "fe_test=newModel.predict(([x_test1,x_test2]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-Jjb2vA9PDW",
        "colab_type": "code",
        "outputId": "a9b04508-84f9-40f0-9840-d570f5c433b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "fe_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(53327, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF1q0OdjMElb",
        "colab_type": "text"
      },
      "source": [
        "# Xgboost model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PV7KZDQRu-LV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "import xgboost as xgb\n",
        "xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.2,\n",
        "                alpha = 10, n_estimators = 50)\n",
        "knn_reg=KNeighborsRegressor(n_neighbors=3,weights='uniform')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFLSRHr5L_Zq",
        "colab_type": "code",
        "outputId": "0bcc9fd8-e1c9-4bb9-9a24-4fb13d93b396",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "xgb_train_time=time.time()\n",
        "xg_reg.fit(fe_train,y_train)\n",
        "xgb_train_time=time.time()-xgb_train_time"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:11:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "io_F8KQrMHRB",
        "colab_type": "text"
      },
      "source": [
        "# Knn model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPnPrJsUNvdz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "knn_train_time=time.time()\n",
        "knn_reg.fit(fe_train,y_train)\n",
        "knn_train_time=time.time()-knn_train_time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4iKttUXMIRy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xgb_predict_time=time.time()\n",
        "xgb_train_pred=xg_reg.predict(fe_train)\n",
        "xgb_val_pred=xg_reg.predict(fe_val)\n",
        "xgb_test_pred=xg_reg.predict(fe_test)\n",
        "xgb_predict_time=time.time()-xgb_predict_time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtD5lpak2Lbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "knn_predict_time=time.time()\n",
        "knn_train_pred=knn_reg.predict(fe_train)\n",
        "knn_val_pred=knn_reg.predict(fe_val)\n",
        "knn_test_pred=knn_reg.predict(fe_test)\n",
        "knn_predict_time=time.time()-knn_predict_time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkCCpOKW2zS5",
        "colab_type": "code",
        "outputId": "27b49493-c305-4b35-bc86-80adbd30d8a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "\n",
        "xgb_rmse_train = sqrt(mean_squared_error(y_train, xgb_train_pred))\n",
        "xgb_rmse_val = sqrt(mean_squared_error(y_val, xgb_val_pred))\n",
        "xgb_rmse_test = sqrt(mean_squared_error(y_test, xgb_test_pred))\n",
        "xgb_mae_train=mean_absolute_error(y_train, xgb_train_pred)\n",
        "xgb_mae_val=mean_absolute_error(y_val, xgb_val_pred)\n",
        "xgb_mae_test=mean_absolute_error(y_test, xgb_test_pred)\n",
        "print('******************XGB***********************')\n",
        "print(\"TRAIN: RMSE: %f , MAE: %f\" % (xgb_rmse_train,xgb_mae_train))\n",
        "print(\"VALIDATE: RMSE: %f , MAE: %f\" % (xgb_rmse_val,xgb_mae_val))\n",
        "print(\"TEST: RMSE: %f , MAE: %f\" % (xgb_rmse_test,xgb_mae_test))\n",
        "print('training time : ' + str(xgb_train_time))\n",
        "print('prediction time : ' + str(xgb_predict_time))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "******************XGB***********************\n",
            "TRAIN: RMSE: 0.529514 , MAE: 0.433945\n",
            "VALIDATE: RMSE: 0.534574 , MAE: 0.438108\n",
            "TEST: RMSE: 0.534010 , MAE: 0.437845\n",
            "training time : 5.471521377563477\n",
            "prediction time : 0.12833356857299805\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNLb8-a8MWuy",
        "colab_type": "code",
        "outputId": "c5b45392-85d3-4f7a-a963-7f25b80b2325",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "knn_rmse_train = sqrt(mean_squared_error(y_train, knn_train_pred))\n",
        "knn_rmse_val = sqrt(mean_squared_error(y_val, knn_val_pred))\n",
        "knn_rmse_test = sqrt(mean_squared_error(y_test, knn_test_pred))\n",
        "knn_mae_train=mean_absolute_error(y_train, knn_train_pred)\n",
        "knn_mae_val=mean_absolute_error(y_val, knn_val_pred)\n",
        "knn_mae_test=mean_absolute_error(y_test, knn_test_pred)\n",
        "print('******************KNN***********************')\n",
        "print(\"TRAIN: RMSE: %f , MAE: %f\" % (knn_rmse_train,knn_mae_train))\n",
        "print(\"VALIDATE: RMSE: %f , MAE: %f\" % (knn_rmse_val,knn_mae_val))\n",
        "print(\"TEST: RMSE: %f , MAE: %f\" % (knn_rmse_test,knn_mae_test))\n",
        "print('training time : ' + str(knn_train_time))\n",
        "print('prediction time : ' + str(knn_predict_time))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "******************KNN***********************\n",
            "TRAIN: RMSE: 0.437820 , MAE: 0.349824\n",
            "VALIDATE: RMSE: 0.616387 , MAE: 0.499122\n",
            "TEST: RMSE: 0.612174 , MAE: 0.494942\n",
            "training time : 0.9693400859832764\n",
            "prediction time : 689.6705441474915\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ojpoNoNMNfP",
        "colab_type": "text"
      },
      "source": [
        "# Compration between all of models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4AmAy78-I1R",
        "colab_type": "code",
        "outputId": "f328e0ef-c521-4459-b6e1-a006cb444d30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "indices = np.arange(4)\n",
        "clf_names=['linear regression','LSTM','xgboost','knn']\n",
        "training_time=[lr_time,siam_time,xgb_train_time,knn_train_time]\n",
        "test_time=[lr_pred_time,siam_pred_time,xgb_predict_time,knn_predict_time]\n",
        "rmse=[lr_rmse_test,lstm_rmse_test,xgb_rmse_test,knn_rmse_test]\n",
        "training_time = np.array(training_time) / np.max(training_time)\n",
        "test_time = np.array(test_time) / np.max(test_time)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.title(\"Score\")\n",
        "plt.barh(indices, rmse, .2, label=\"rmse\", color='navy')\n",
        "plt.barh(indices + .3, training_time, .2, label=\"training time\",\n",
        "         color='c')\n",
        "plt.barh(indices + .6, test_time, .2, label=\"test time\", color='darkorange')\n",
        "plt.yticks(())\n",
        "plt.legend(loc='best')\n",
        "plt.subplots_adjust(left=.25)\n",
        "plt.subplots_adjust(top=.95)\n",
        "plt.subplots_adjust(bottom=.05)\n",
        "\n",
        "for i, c in zip(indices, clf_names):\n",
        "    plt.text(-.3, i, c)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuAAAAI1CAYAAACXLU+VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1YEBXIJ_fIJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_s1=train['product_title']\n",
        "train_s2=train['search_term']\n",
        "y=train['relevance']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9V4DyKSSwys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from collections import Counter\n",
        "# unique_symbols = Counter()\n",
        "\n",
        "# for _, message in train_s1.iteritems():\n",
        "#     unique_symbols.update(message)\n",
        "    \n",
        "# print(\"Unique symbols:\", len(unique_symbols))\n",
        "\n",
        "\n",
        "# # Find symbols that appear fewer times than the threshold:\n",
        "\n",
        "# uncommon_symbols = list()\n",
        "\n",
        "# for symbol, count in unique_symbols.items():\n",
        "#     if count < 5:\n",
        "#         uncommon_symbols.append(symbol)\n",
        "\n",
        "# print(\"Uncommon symbols:\", len(uncommon_symbols))\n",
        "\n",
        "\n",
        "# # Replace them with a placeholder:\n",
        "\n",
        "# DUMMY = uncommon_symbols[0]\n",
        "# tr_table = str.maketrans(\"\".join(uncommon_symbols), DUMMY * len(uncommon_symbols))\n",
        "\n",
        "# train_s1 = train_s1.apply(lambda x: x.translate(tr_table))\n",
        "\n",
        "\n",
        "# # We will need the number of unique symbols further down when we will decide on the dimensionality of inputs.\n",
        "\n",
        "# num_unique_symbols = len(unique_symbols) - len(uncommon_symbols) + 1 \n",
        "max_length1 = train_s1.map(len).max()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_z4mckLP0Ew",
        "colab_type": "text"
      },
      "source": [
        "Tokenizer of product_title feture by words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hcgt80JbSz_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(\n",
        "    # char_level=True,\n",
        "    lower=False,\n",
        ")\n",
        "\n",
        "tokenizer.fit_on_texts(train_s1)\n",
        "train_s1_seq = tokenizer.texts_to_sequences(train_s1)\n",
        "train_s1_seq = pad_sequences(train_s1_seq, maxlen=max_length1, padding='post')\n",
        "vocab_size1 = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4mTwUl5S3Qe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from collections import Counter\n",
        "# unique_symbols = Counter()\n",
        "\n",
        "# for _, message in train_s2.iteritems():\n",
        "#     unique_symbols.update(message)\n",
        "    \n",
        "# print(\"Unique symbols:\", len(unique_symbols))\n",
        "\n",
        "\n",
        "# # Find symbols that appear fewer times than the threshold:\n",
        "\n",
        "# uncommon_symbols = list()\n",
        "\n",
        "# for symbol, count in unique_symbols.items():\n",
        "#     if count < 5:\n",
        "#         uncommon_symbols.append(symbol)\n",
        "\n",
        "# print(\"Uncommon symbols:\", len(uncommon_symbols))\n",
        "\n",
        "\n",
        "# # Replace them with a placeholder:\n",
        "\n",
        "# DUMMY = uncommon_symbols[0]\n",
        "# tr_table = str.maketrans(\"\".join(uncommon_symbols), DUMMY * len(uncommon_symbols))\n",
        "\n",
        "# train_s2 = train_s2.apply(lambda x: x.translate(tr_table))\n",
        "\n",
        "\n",
        "# # We will need the number of unique symbols further down when we will decide on the dimensionality of inputs.\n",
        "\n",
        "# num_unique_symbols2 = len(unique_symbols) - len(uncommon_symbols) + 1 \n",
        "\n",
        "max_length2 = train_s2.map(len).max()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mk7nAi0nP4qW",
        "colab_type": "text"
      },
      "source": [
        "Tokenizer of search_term feture by words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhD3zJe4S7G1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(\n",
        "    # char_level=True,\n",
        "    # filters=None,\n",
        "    lower=False,\n",
        ")\n",
        "tokenizer.fit_on_texts(train_s2)\n",
        "train_s2_seq = tokenizer.texts_to_sequences(train_s2)\n",
        "train_s2_seq = pad_sequences(train_s2_seq, maxlen=max_length1, padding='post')\n",
        "vocab_size2 = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_txa72FHArW",
        "colab_type": "text"
      },
      "source": [
        "# Model based word level with embedded layer\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOCmocoiTbL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train1, x_test1, y_train, y_test = train_test_split(train_s1_seq, y, test_size=0.2)\n",
        "x_train2, x_test2, y_train2, y_test = train_test_split(train_s2_seq, y, test_size=0.2)\n",
        "x_train1, x_val1, y_train, y_val = train_test_split(x_train1, y_train, test_size=0.1)\n",
        "x_train2, x_val2, y_train2, y_val = train_test_split(x_train2, y_train2, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqnBKImGUj5l",
        "colab_type": "code",
        "outputId": "7a8533f9-d4f8-44b2-c814-266c3f59b660",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import keras.backend as K\n",
        "def cosine_distance(vests):\n",
        "    x, y = vests\n",
        "    x = K.l2_normalize(x, axis=-1)\n",
        "    y = K.l2_normalize(y, axis=-1)\n",
        "    return -K.mean(x * y, axis=-1, keepdims=True)\n",
        "\n",
        "\n",
        "def cos_dist_output_shape(shapes):\n",
        "    shape1, shape2 = shapes\n",
        "    return (shape1[0],1)\n",
        "input_1 = Input(shape=(max_length1,))\n",
        "input_2 = Input(shape=(max_length1,))\n",
        "\n",
        "emb_1 = Embedding(vocab_size1, 64,input_shape=(max_length1,))(input_1)#, input_shape=(1,max_length1)\n",
        "emb_2 = Embedding(vocab_size2, 64,input_shape=(max_length1,))(input_2)#, input_shape=(1,max_length2)\n",
        "\n",
        "common_lstm = LSTM(64,return_sequences=True, activation=\"relu\")\n",
        "vector_1 = common_lstm(emb_1)\n",
        "vector_1 = Flatten()(vector_1)\n",
        "\n",
        "vector_2 = common_lstm(emb_2)\n",
        "vector_2 = Flatten()(vector_2)\n",
        "\n",
        "x3 = Subtract()([vector_1, vector_2])\n",
        "x4= Add()([vector_1, vector_2])\n",
        "x5=Multiply()([vector_1, vector_2])\n",
        "\n",
        "conc = Concatenate(axis=-1)([x5,x4, x3])\n",
        "\n",
        "x = Dense(100, activation=\"relu\", name='conc_layer')(conc)\n",
        "x = Dropout(0.01)(x)\n",
        "out = Dense(1, activation=\"relu\", name = 'out')(x)\n",
        "\n",
        "model = Model([input_1, input_2], out)\n",
        "\n",
        "model.compile(loss=\"mae\", optimizer=Adam(0.00001))\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 136)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 136)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 136, 64)      1084672     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 136, 64)      444672      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 136, 64)      33024       embedding_1[0][0]                \n",
            "                                                                 embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 8704)         0           lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 8704)         0           lstm_1[1][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "multiply_1 (Multiply)           (None, 8704)         0           flatten_1[0][0]                  \n",
            "                                                                 flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 8704)         0           flatten_1[0][0]                  \n",
            "                                                                 flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "subtract_1 (Subtract)           (None, 8704)         0           flatten_1[0][0]                  \n",
            "                                                                 flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 26112)        0           multiply_1[0][0]                 \n",
            "                                                                 add_1[0][0]                      \n",
            "                                                                 subtract_1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conc_layer (Dense)              (None, 100)          2611300     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 100)          0           conc_layer[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "out (Dense)                     (None, 1)            101         dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 4,173,769\n",
            "Trainable params: 4,173,769\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkhsxqrBU3qG",
        "colab_type": "code",
        "outputId": "e8d26852-4057-4e8d-cb7c-102c05e5e923",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import time\n",
        "siam_time=time.time()\n",
        "model.fit([x_train1,x_train2],y_train.values.reshape(-1,1), epochs = 20,\n",
        "          batch_size=64, validation_data=([x_val1, x_val2],y_val.values.reshape(-1,1)))\n",
        "siam_time=time.time()-siam_time"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 53327 samples, validate on 5926 samples\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "53327/53327 [==============================] - 370s 7ms/step - loss: 0.7661 - val_loss: 0.4335\n",
            "Epoch 2/20\n",
            "53327/53327 [==============================] - 357s 7ms/step - loss: 0.4408 - val_loss: 0.4361\n",
            "Epoch 3/20\n",
            "53327/53327 [==============================] - 353s 7ms/step - loss: 0.4405 - val_loss: 0.4344\n",
            "Epoch 4/20\n",
            "53327/53327 [==============================] - 349s 7ms/step - loss: 0.4396 - val_loss: 0.4315\n",
            "Epoch 5/20\n",
            "53327/53327 [==============================] - 350s 7ms/step - loss: 0.4385 - val_loss: 0.4342\n",
            "Epoch 6/20\n",
            "53327/53327 [==============================] - 352s 7ms/step - loss: 0.4371 - val_loss: 0.4336\n",
            "Epoch 7/20\n",
            "53327/53327 [==============================] - 351s 7ms/step - loss: 0.4356 - val_loss: 0.4337\n",
            "Epoch 8/20\n",
            "53327/53327 [==============================] - 351s 7ms/step - loss: 0.4326 - val_loss: 0.4355\n",
            "Epoch 9/20\n",
            "53327/53327 [==============================] - 351s 7ms/step - loss: 0.4292 - val_loss: 0.4377\n",
            "Epoch 10/20\n",
            "53327/53327 [==============================] - 349s 7ms/step - loss: 0.4263 - val_loss: 0.4410\n",
            "Epoch 11/20\n",
            "53327/53327 [==============================] - 351s 7ms/step - loss: 0.4232 - val_loss: 0.4409\n",
            "Epoch 12/20\n",
            "53327/53327 [==============================] - 351s 7ms/step - loss: 0.4213 - val_loss: 0.4429\n",
            "Epoch 13/20\n",
            "53327/53327 [==============================] - 352s 7ms/step - loss: 0.4184 - val_loss: 0.4460\n",
            "Epoch 14/20\n",
            "53327/53327 [==============================] - 348s 7ms/step - loss: 0.4159 - val_loss: 0.4457\n",
            "Epoch 15/20\n",
            "53327/53327 [==============================] - 346s 6ms/step - loss: 0.4131 - val_loss: 0.4477\n",
            "Epoch 16/20\n",
            "53327/53327 [==============================] - 346s 6ms/step - loss: 0.4102 - val_loss: 0.4490\n",
            "Epoch 17/20\n",
            "53327/53327 [==============================] - 349s 7ms/step - loss: 0.4076 - val_loss: 0.4504\n",
            "Epoch 18/20\n",
            "53327/53327 [==============================] - 349s 7ms/step - loss: 0.4037 - val_loss: 0.4525\n",
            "Epoch 19/20\n",
            "53327/53327 [==============================] - 348s 7ms/step - loss: 0.4008 - val_loss: 0.4554\n",
            "Epoch 20/20\n",
            "53327/53327 [==============================] - 347s 7ms/step - loss: 0.3981 - val_loss: 0.4570\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJA-x9bXJaIN",
        "colab_type": "text"
      },
      "source": [
        "Evaluation by RMSE and MAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1XbiqGcU-6o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "siam_pred_time=time.time()\n",
        "siam_train_pred=model.predict([x_train1,x_train2])\n",
        "siam_val_pred=model.predict([x_val1, x_val2])\n",
        "siam_test_pred=model.predict([x_test1, x_test2])\n",
        "siam_pred_time=time.time()-siam_pred_time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5qeZMGoVNTT",
        "colab_type": "code",
        "outputId": "044ff8e0-da51-49e6-c747-a8a089138510",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
        "from math import sqrt\n",
        "lstm_rmse_train = sqrt(mean_squared_error(y_train, siam_train_pred))\n",
        "lstm_rmse_val = sqrt(mean_squared_error(y_val, siam_val_pred))\n",
        "lstm_rmse_test = sqrt(mean_squared_error(y_test, siam_test_pred))\n",
        "lstm_mae_train=mean_absolute_error(y_train, siam_train_pred)\n",
        "lstm_mae_val=mean_absolute_error(y_val, siam_val_pred)\n",
        "lstm_mae_test=mean_absolute_error(y_test, siam_test_pred)\n",
        "print('******************LSTM***********************')\n",
        "print(\"TRAIN: RMSE: %f , MAE: %f\" % (lstm_rmse_train,lstm_mae_train))\n",
        "print(\"VALIDATE: RMSE: %f , MAE: %f\" % (lstm_rmse_val,lstm_mae_val))\n",
        "print(\"TEST: RMSE: %f , MAE: %f\" % (lstm_rmse_test,lstm_mae_test))\n",
        "print('taining time : ' + str(siam_time))\n",
        "print('prediction time : ' + str(siam_pred_time))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "******************LSTM***********************\n",
            "TRAIN: RMSE: 0.501700 , MAE: 0.392473\n",
            "VALIDATE: RMSE: 0.569931 , MAE: 0.456952\n",
            "TEST: RMSE: 0.566717 , MAE: 0.458565\n",
            "taining time : 7021.600814580917\n",
            "prediction time : 332.92998361587524\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnbsq5xhOUzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8OIuCKAVXru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LinearRegression\n",
        " #dummy function for CountVectorizer\n",
        "def dummy_fun(doc):\n",
        "    return doc\n",
        "\n",
        "lr_model=Pipeline([('vect', CountVectorizer(analyzer='word',\n",
        "     tokenizer=dummy_fun,\n",
        "     preprocessor=dummy_fun,\n",
        "     token_pattern=None)),\n",
        "               ('clf', LinearRegression())\n",
        "              ])\n",
        "train['combined'] = train[['product_title', 'search_term']].apply(lambda x: ''.join(x), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBVSo24vWTLI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_chars(df):\n",
        "  data=df.copy()\n",
        "  data['combined']=data['combined'].apply(lambda x: [char for char in x if char != ' '])\n",
        "  return data\n",
        "#train=split_chars(train)\n",
        "train['combined']=train['combined'].astype(str)\n",
        "lr_train, lr_test, y_train, y_test = train_test_split(train['combined'], y, test_size=0.2)\n",
        "lr_train, lr_val, y_train, y_val = train_test_split(lr_train, y_train, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3GjpEw3Wd91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_time=time.time()\n",
        "lr_model.fit(lr_train,y_train)\n",
        "lr_time=time.time()-lr_time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jo5VXVLFWpCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_pred_time=time.time()\n",
        "lr_val_pred=lr_model.predict(lr_val)\n",
        "lr_test_pred=lr_model.predict(lr_test)\n",
        "lr_train_pred=lr_model.predict(lr_train)\n",
        "lr_pred_time=time.time()-lr_pred_time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg0zMEYeWqSK",
        "colab_type": "code",
        "outputId": "67128760-1a28-4de5-e06e-a7f025d9130f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
        "from math import sqrt\n",
        "lr_rmse_train = sqrt(mean_squared_error(y_train, lr_train_pred))\n",
        "lr_rmse_val = sqrt(mean_squared_error(y_val, lr_val_pred))\n",
        "lr_rmse_test = sqrt(mean_squared_error(y_test, lr_test_pred))\n",
        "lr_mae_train=mean_absolute_error(y_train, lr_train_pred)\n",
        "lr_mae_val=mean_absolute_error(y_val, lr_val_pred)\n",
        "lr_mae_test=mean_absolute_error(y_test, lr_test_pred)\n",
        "print('******************naive linear regression***********************')\n",
        "print(\"TRAIN: RMSE: %f , MAE: %f\" % (lr_rmse_train,lr_mae_train))\n",
        "print(\"VALIDATE: RMSE: %f , MAE: %f\" % (lr_rmse_val,lr_mae_val))\n",
        "print(\"TEST: RMSE: %f , MAE: %f\" % (lr_rmse_test,lr_mae_test))\n",
        "print('test time : ' + str(lr_time))\n",
        "print('prediction time : ' + str(lr_pred_time))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "******************naive linear regression***********************\n",
            "TRAIN: RMSE: 0.531310 , MAE: 0.435590\n",
            "VALIDATE: RMSE: 0.528879 , MAE: 0.432180\n",
            "TEST: RMSE: 0.530700 , MAE: 0.435868\n",
            "test time : 1.8427410125732422\n",
            "prediction time : 1.3176956176757812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XhMA0OmLnUw",
        "colab_type": "text"
      },
      "source": [
        "#Features extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KD6N6g1RWq6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_extract=model.layers[-3].output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzhvVxlLXOMy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "newModel=Model([input_1, input_2], feature_extract)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTn5oO2qXOqy",
        "colab_type": "code",
        "outputId": "b8eca7e7-bac2-4dd3-cc8c-e2e82d19d4e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        }
      },
      "source": [
        "newModel.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 136)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 136)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 136, 64)      1084672     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 136, 64)      444672      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 136, 64)      33024       embedding_1[0][0]                \n",
            "                                                                 embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 8704)         0           lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 8704)         0           lstm_1[1][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "multiply_1 (Multiply)           (None, 8704)         0           flatten_1[0][0]                  \n",
            "                                                                 flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 8704)         0           flatten_1[0][0]                  \n",
            "                                                                 flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "subtract_1 (Subtract)           (None, 8704)         0           flatten_1[0][0]                  \n",
            "                                                                 flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 26112)        0           multiply_1[0][0]                 \n",
            "                                                                 add_1[0][0]                      \n",
            "                                                                 subtract_1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conc_layer (Dense)              (None, 100)          2611300     concatenate_1[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 4,173,668\n",
            "Trainable params: 4,173,668\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKUzaPRJXO8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fe_train=newModel.predict(([x_train1,x_train2]))\n",
        "fe_val=newModel.predict(([x_val1,x_val2]))\n",
        "fe_test=newModel.predict(([x_test1,x_test2]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHxNi_-VXdZW",
        "colab_type": "code",
        "outputId": "b28c3fff-72f6-496c-cec0-8ea464a81b38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "fe_train.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(53327, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTko73JwLpvW",
        "colab_type": "text"
      },
      "source": [
        "# Xgboost model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjbKK_SMXdf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "import xgboost as xgb\n",
        "xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.2,\n",
        "                alpha = 10, n_estimators = 50)\n",
        "knn_reg=KNeighborsRegressor(n_neighbors=3,weights='uniform')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmDyRzuGXdlo",
        "colab_type": "code",
        "outputId": "cb866403-a237-484d-8b71-2fcea3c06288",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "xgb_train_time=time.time()\n",
        "xg_reg.fit(fe_train,y_train)\n",
        "xgb_train_time=time.time()-xgb_train_time"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[12:06:41] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6DKVdGMXPHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "knn_train_time=time.time()\n",
        "knn_reg.fit(fe_train,y_train)\n",
        "knn_train_time=time.time()-knn_train_time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX6hrg87Xtyi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xgb_predict_time=time.time()\n",
        "xgb_train_pred=xg_reg.predict(fe_train)\n",
        "xgb_val_pred=xg_reg.predict(fe_val)\n",
        "xgb_test_pred=xg_reg.predict(fe_test)\n",
        "xgb_predict_time=time.time()-xgb_predict_time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XHKsOHzL0ro",
        "colab_type": "text"
      },
      "source": [
        "# Knn model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHL7xqBFXtub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "knn_predict_time=time.time()\n",
        "knn_train_pred=knn_reg.predict(fe_train)\n",
        "knn_val_pred=knn_reg.predict(fe_val)\n",
        "knn_test_pred=knn_reg.predict(fe_test)\n",
        "knn_predict_time=time.time()-knn_predict_time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLXn20J4YCcM",
        "colab_type": "code",
        "outputId": "3a6c4c63-09d8-486e-de59-ed720139b92b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "xgb_rmse_train = sqrt(mean_squared_error(y_train, xgb_train_pred))\n",
        "xgb_rmse_val = sqrt(mean_squared_error(y_val, xgb_val_pred))\n",
        "xgb_rmse_test = sqrt(mean_squared_error(y_test, xgb_test_pred))\n",
        "xgb_mae_train=mean_absolute_error(y_train, xgb_train_pred)\n",
        "xgb_mae_val=mean_absolute_error(y_val, xgb_val_pred)\n",
        "xgb_mae_test=mean_absolute_error(y_test, xgb_test_pred)\n",
        "print('******************XGB***********************')\n",
        "print(\"TRAIN: RMSE: %f , MAE: %f\" % (xgb_rmse_train,xgb_mae_train))\n",
        "print(\"VALIDATE: RMSE: %f , MAE: %f\" % (xgb_rmse_val,xgb_mae_val))\n",
        "print(\"TEST: RMSE: %f , MAE: %f\" % (xgb_rmse_test,xgb_mae_test))\n",
        "print('training time : ' + str(xgb_train_time))\n",
        "print('prediction time : ' + str(xgb_predict_time))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "******************XGB***********************\n",
            "TRAIN: RMSE: 0.530651 , MAE: 0.434991\n",
            "VALIDATE: RMSE: 0.532089 , MAE: 0.434957\n",
            "TEST: RMSE: 0.534054 , MAE: 0.439044\n",
            "training time : 4.433581113815308\n",
            "prediction time : 0.15568089485168457\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQgOakiNXtsr",
        "colab_type": "code",
        "outputId": "6505c4e5-df9d-4570-adcc-0ec216d10a6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "knn_rmse_train = sqrt(mean_squared_error(y_train, knn_train_pred))\n",
        "knn_rmse_val = sqrt(mean_squared_error(y_val, knn_val_pred))\n",
        "knn_rmse_test = sqrt(mean_squared_error(y_test, knn_test_pred))\n",
        "knn_mae_train=mean_absolute_error(y_train, knn_train_pred)\n",
        "knn_mae_val=mean_absolute_error(y_val, knn_val_pred)\n",
        "knn_mae_test=mean_absolute_error(y_test, knn_test_pred)\n",
        "print('******************KNN***********************')\n",
        "print(\"TRAIN: RMSE: %f , MAE: %f\" % (knn_rmse_train,knn_mae_train))\n",
        "print(\"VALIDATE: RMSE: %f , MAE: %f\" % (knn_rmse_val,knn_mae_val))\n",
        "print(\"TEST: RMSE: %f , MAE: %f\" % (knn_rmse_test,knn_mae_test))\n",
        "print('training time : ' + str(knn_train_time))\n",
        "print('prediction time : ' + str(knn_predict_time))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "******************KNN***********************\n",
            "TRAIN: RMSE: 0.434913 , MAE: 0.347674\n",
            "VALIDATE: RMSE: 0.611450 , MAE: 0.492954\n",
            "TEST: RMSE: 0.615343 , MAE: 0.496404\n",
            "training time : 0.8067502975463867\n",
            "prediction time : 58.14159274101257\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRFO0Y5vMlpt",
        "colab_type": "text"
      },
      "source": [
        "# Compration between all of models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0p5bwyktXtp-",
        "colab_type": "code",
        "outputId": "32772342-f59a-43cf-e563-446cc77e9112",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "indices = np.arange(4)\n",
        "clf_names=['linear regression','LSTM','xgboost','knn']\n",
        "training_time=[lr_time,siam_time,xgb_train_time,knn_train_time]\n",
        "test_time=[lr_pred_time,siam_pred_time,xgb_predict_time,knn_predict_time]\n",
        "rmse=[lr_rmse_test,lstm_rmse_test,xgb_rmse_test,knn_rmse_test]\n",
        "training_time = np.array(training_time) / np.max(training_time)\n",
        "test_time = np.array(test_time) / np.max(test_time)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.title(\"Score\")\n",
        "plt.barh(indices, rmse, .2, label=\"rmse\", color='navy')\n",
        "plt.barh(indices + .3, training_time, .2, label=\"training time\",\n",
        "         color='c')\n",
        "plt.barh(indices + .6, test_time, .2, label=\"test time\", color='darkorange')\n",
        "plt.yticks(())\n",
        "plt.legend(loc='best')\n",
        "plt.subplots_adjust(left=.25)\n",
        "plt.subplots_adjust(top=.95)\n",
        "plt.subplots_adjust(bottom=.05)\n",
        "\n",
        "for i, c in zip(indices, clf_names):\n",
        "    plt.text(-.3, i, c)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuAAAAI1CAYAAACXLU+VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}